{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# HW3B - Pandas Fundamentals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "See Canvas for details on how to complete and submit this assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "This assignment transitions you from NumPy's numerical array operations to Pandas' powerful tabular data manipulation. While NumPy excels at homogeneous numerical arrays, Pandas is designed for the heterogeneous, labeled data that characterizes most real-world datasets—mixing dates, categories, numbers, and text within the same table.\n",
    "\n",
    "You'll work with real bike share data from Chicago's Divvy system to answer questions about urban transportation patterns. Through three progressively complex problems—exploring usage patterns, analyzing rider behavior, and conducting temporal analysis—you'll discover why Pandas has become the standard tool for data analysis in Python.\n",
    "\n",
    "The assignment emphasizes Pandas' design philosophy: named column access, explicit indexing methods (loc/iloc), handling missing data, and method chaining for readable data pipelines. You'll also see how Pandas builds on NumPy while adding the structure and convenience needed for practical data science work.\n",
    "\n",
    "This assignment should take 3-5 hours to complete.\n",
    "\n",
    "Before submitting, ensure your notebook:\n",
    "\n",
    "- Runs completely with \"Kernel → Restart & Run All\"\n",
    "- Includes thoughtful responses to all interpretation questions\n",
    "- Uses clear variable names and follows good coding practices\n",
    "- Shows your work (don't just print final answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "### Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "By completing this assignment, you will be able to:\n",
    "\n",
    "1. **Construct and manipulate Pandas data structures**\n",
    "   - Create DataFrames from dictionaries and CSV files\n",
    "   - Distinguish between Series and DataFrame objects\n",
    "   - Set and reset index structures appropriately\n",
    "   - Understand when operations return views vs copies\n",
    "2. **Apply explicit indexing paradigms**\n",
    "   - Use `loc[]` for label-based data access\n",
    "   - Use `iloc[]` for position-based data access\n",
    "   - Access columns using bracket notation\n",
    "   - Explain when each indexing method is appropriate\n",
    "3. **Diagnose and explore datasets systematically**\n",
    "   - Use `info()`, `describe()`, `head()`, and `dtypes` to understand data structure\n",
    "   - Identify missing values with `isna()` and `notna()`\n",
    "   - Calculate summary statistics across different axes\n",
    "   - Interpret value distributions with `value_counts()`\n",
    "4. **Filter data with boolean indexing and queries**\n",
    "   - Combine multiple conditions with `&`, `|`, and `~` operators\n",
    "   - Use `isin()` for membership testing\n",
    "   - Apply `query()` for readable complex filters\n",
    "   - Understand how index alignment affects operations\n",
    "5. **Work with datetime data**\n",
    "   - Parse dates during CSV loading\n",
    "   - Extract temporal components with the `.dt` accessor\n",
    "   - Filter data by date ranges\n",
    "   - Create time-based derived features\n",
    "6. **Connect Pandas patterns to data analysis workflows**\n",
    "   - Formulate questions that data can answer\n",
    "   - Choose appropriate methods for different analysis tasks\n",
    "   - Interpret results in domain context\n",
    "   - Recognize when vectorized operations outperform apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### Generative AI Allowance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "You may use GenAI tools for brainstorming, explanations, and code sketches if you disclose it, understand it, and validate it. Your submission must represent your own work and you are solely responsible for its correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "Total of 90 points available, will be graded out of 80. Scores of >100% are allowed.\n",
    "\n",
    "Distribution:\n",
    "\n",
    "- Tasks: 48 pts\n",
    "- Interpretation: 32 pts\n",
    "- Reflection: 10 pts\n",
    "\n",
    "Points by Problem:\n",
    "\n",
    "- Problem 1: 3 tasks, 10 pts\n",
    "- Problem 2: 4 tasks, 14 pts\n",
    "- Problem 3: 4 tasks, 14 pts\n",
    "- Problem 4: 3 tasks, 10 pts\n",
    "\n",
    "Interpretation Questions:\n",
    "\n",
    "- Problem 1: 3 questions, 8 pts\n",
    "- Problem 2: 4 questions, 8 pts\n",
    "- Problem 3: 3 questions, 8 pts\n",
    "- Problem 4: 3 questions, 8 pts\n",
    "\n",
    "Graduate differentiation: poor follow-up responses will result in up to a 5pt deduction for that problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Dataset: Chicago Divvy Bike Share"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "The dataset you will analyze is based on real trip information from Divvy, Chicago's bike share system. It contains individual trips with start/end times, station information, and rider type.\n",
    "\n",
    "Dataset homepage: https://divvybikes.com/system-data\n",
    "\n",
    "Each trip includes:\n",
    "\n",
    "- Trip start and end times (datetime)\n",
    "- Start and end station names and IDs\n",
    "- Rider type (member vs casual)\n",
    "- Bike type (classic, electric, or docked)\n",
    "\n",
    "Chicago's Department of Transportation uses this data to optimize station placement, understand usage patterns, and improve service. You'll explore similar questions that real transportation analysts investigate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### Problem 1: Creating DataFrames from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Before loading data from files, you need to understand how Pandas structures are built. In this problem, you'll create Series and DataFrames manually using Python's built-in data structures. This is a quick warmup to establish the fundamentals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### Task 1a: Create a Series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "Create a Series called `temperatures` representing daily high temperatures for a week:\n",
    "\n",
    "- Monday: 72°F\n",
    "- Tuesday: 75°F  \n",
    "- Wednesday: 68°F\n",
    "- Thursday: 71°F\n",
    "- Friday: 73°F\n",
    "\n",
    "Use the day names as the index. Print the Series and its data type."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monday       72\n",
      "Tuesday      75\n",
      "Wednesday    68\n",
      "Thursday     71\n",
      "Friday       73\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "temperatures = pd.Series([72, 75, 68, 71, 73], index=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"])\n",
    "print(temperatures)\n",
    "#print(table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "#### Task 1b: Create a DataFrame from a Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "Create a DataFrame called `products` with the following data:\n",
    "\n",
    "| product | price | quantity |\n",
    "|---------|-------|----------|\n",
    "| Widget  | 19.99 | 100 |\n",
    "| Gadget  | 24.99 | 75 |\n",
    "| Doohickey | 12.49 | 150 |\n",
    "\n",
    "Use a dictionary where keys are column names and values are lists. Print the DataFrame and report its shape."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     product  price  quantity\n",
      "0     Widget  19.99       100\n",
      "1     Gadget  24.99        75\n",
      "2  Doohickey  12.49       150\n",
      "\n",
      "Data Frame Shape: (3, 3)\n"
     ]
    }
   ],
   "source": [
    "products = pd.DataFrame({\n",
    "    'product': ['Widget', 'Gadget', 'Doohickey'],\n",
    "    'price': [19.99, 24.99, 12.49],\n",
    "    'quantity': [100, 75, 150]\n",
    "})\n",
    "print(products)\n",
    "print(\"\\nData Frame Shape:\", products.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Task 1c: Access DataFrame Elements"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "Using the `products` DataFrame from Task 1b, extract and print:\n",
    "\n",
    "1. The `price` column as a Series\n",
    "2. The `product` and `quantity` columns as a DataFrame (using a list of column names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    19.99\n",
      "1    24.99\n",
      "2    12.49\n",
      "Name: price, dtype: float64\n",
      "     product  quantity\n",
      "0     Widget       100\n",
      "1     Gadget        75\n",
      "2  Doohickey       150\n"
     ]
    }
   ],
   "source": [
    "price = pd.Series(products[\"price\"])\n",
    "print(price)\n",
    "\n",
    "prod_quant = pd.DataFrame(products,columns=['product', 'quantity'])\n",
    "print(prod_quant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "Answer the following questions (briefly / concisely) in the markdown cell below:\n",
    "\n",
    "1. Data structure mapping: When you create a DataFrame from a dictionary (like in Task 1b), what do the dictionary keys become? What do the values become?\n",
    "2. Bracket notation: Why does `df['price']` return a Series, but `df[['price']]` return a DataFrame? What's the difference in what you're asking for?\n",
    "3. Index purpose: In Task 1a, you used day names as the index instead of default numbers (0, 1, 2...). When would a custom index like this be more useful than the default numeric index?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "##### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "*Problem 1 interpretation here*\n",
    "\n",
    "1. The dictionary keys become the column headers and the values become the column data\n",
    "\n",
    "2. Because columns are series in dataframes. A series is a 1 dimensional labeled array whereas a dataframe is always two dimensional. This is true for dataframes even when they contain only one column or row. \n",
    "\n",
    "3. It would be more useful if you wanted to call on data from specific column names. Meaning if the column headers have valuable meaning to reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Problem 2: Loading and Initial Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "Before starting this problem, make sure you are working in a copy of this file in the `my_repo` folder you created in HW2a. You must also have a copy of the file `202410-divvy-tripdata-100k.csv` in a subdirectory called `data`. That file structure is illustrated below.\n",
    "\n",
    "```text\n",
    "~/insy6500/my_repo\n",
    "└── homework\n",
    "    ├── data\n",
    "    │   └── 202410-divvy-tripdata-100k.csv\n",
    "    └── hw3b.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### Task 2a: Load and Understand Raw Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34",
   "metadata": {},
   "source": [
    "Start by loading the data \"as-is\" to get a general understanding of the overall structure and how Pandas interprets it by default.\n",
    "\n",
    "Note on file paths: The provided code uses `Path` from Python's `pathlib` module to handle file paths. Path objects work consistently across operating systems (Windows uses backslashes `\\`, Mac/Linux use forward slashes `/`), automatically using the correct separator for your system. The provided code defines `csv_path` which should be used as the filename in your `pd.read_csv` to load the data file.\n",
    "\n",
    "1. Use `pd.read_csv` to load `csv_path` (provided below) without specifying any other arguments. Assign it to the variable `df_raw`.\n",
    "2. Use the methods we described in class to explore the shape, structure, types, etc. of the data. In particular, consider which columns represent dates or categories.\n",
    "3. Note the amount of memory used by the dataset. See the section on memory diagnostics in notebook 07a for appropriate code snippets using `memory_usage`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype  \n",
      "---  ------              --------------   -----  \n",
      " 0   ride_id             100000 non-null  object \n",
      " 1   rideable_type       100000 non-null  object \n",
      " 2   started_at          100000 non-null  object \n",
      " 3   ended_at            100000 non-null  object \n",
      " 4   start_station_name  89623 non-null   object \n",
      " 5   start_station_id    89623 non-null   object \n",
      " 6   end_station_name    89485 non-null   object \n",
      " 7   end_station_id      89485 non-null   object \n",
      " 8   start_lat           100000 non-null  float64\n",
      " 9   start_lng           100000 non-null  float64\n",
      " 10  end_lat             99913 non-null   float64\n",
      " 11  end_lng             99913 non-null   float64\n",
      " 12  member_casual       100000 non-null  object \n",
      "dtypes: float64(4), object(9)\n",
      "memory usage: 9.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>100000.000000</td>\n",
       "      <td>99913.000000</td>\n",
       "      <td>99913.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>41.898817</td>\n",
       "      <td>-87.644839</td>\n",
       "      <td>41.899246</td>\n",
       "      <td>-87.645279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.045897</td>\n",
       "      <td>0.027118</td>\n",
       "      <td>0.046581</td>\n",
       "      <td>0.028055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>41.648501</td>\n",
       "      <td>-87.840000</td>\n",
       "      <td>41.610000</td>\n",
       "      <td>-89.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>41.879356</td>\n",
       "      <td>-87.658902</td>\n",
       "      <td>41.879472</td>\n",
       "      <td>-87.659172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>41.894666</td>\n",
       "      <td>-87.641180</td>\n",
       "      <td>41.894822</td>\n",
       "      <td>-87.641255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>41.925566</td>\n",
       "      <td>-87.627716</td>\n",
       "      <td>41.925858</td>\n",
       "      <td>-87.628579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42.070000</td>\n",
       "      <td>-87.530000</td>\n",
       "      <td>43.930000</td>\n",
       "      <td>-86.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           start_lat      start_lng       end_lat       end_lng\n",
       "count  100000.000000  100000.000000  99913.000000  99913.000000\n",
       "mean       41.898817     -87.644839     41.899246    -87.645279\n",
       "std         0.045897       0.027118      0.046581      0.028055\n",
       "min        41.648501     -87.840000     41.610000    -89.120000\n",
       "25%        41.879356     -87.658902     41.879472    -87.659172\n",
       "50%        41.894666     -87.641180     41.894822    -87.641255\n",
       "75%        41.925566     -87.627716     41.925858    -87.628579\n",
       "max        42.070000     -87.530000     43.930000    -86.050000"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# create a OS-independent pointer to the csv file created by Setup\n",
    "csv_path = Path('~/INSY6500/my_repo/data/202410-divvy-tripdata-100k.csv')\n",
    "df_raw = pd.read_csv(csv_path)\n",
    "df_raw\n",
    "\n",
    "# load and explore the data below (create additional code / markdown cells as necessary)\n",
    "df_raw.info()\n",
    "\n",
    "df_raw.dtypes\n",
    "\n",
    "df_raw.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Task 2b: Reload with Proper Data Types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38",
   "metadata": {},
   "source": [
    "1. Repeat step 2a.1 to reload the data. Use the `dtype` and `parse_dates` arguments to properly assign categorical and date types. Assign the result to the variable name `rides`.\n",
    "2. After loading, use `rides.info()` to confirm the type changes.\n",
    "3. Use `memory_usage` to compare the resulting size with that from step 2a.3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 13 columns):\n",
      " #   Column              Non-Null Count   Dtype         \n",
      "---  ------              --------------   -----         \n",
      " 0   ride_id             100000 non-null  string        \n",
      " 1   rideable_type       100000 non-null  category      \n",
      " 2   started_at          100000 non-null  datetime64[ns]\n",
      " 3   ended_at            100000 non-null  datetime64[ns]\n",
      " 4   start_station_name  89623 non-null   string        \n",
      " 5   start_station_id    89623 non-null   string        \n",
      " 6   end_station_name    89485 non-null   string        \n",
      " 7   end_station_id      89485 non-null   string        \n",
      " 8   start_lat           100000 non-null  float64       \n",
      " 9   start_lng           100000 non-null  float64       \n",
      " 10  end_lat             99913 non-null   float64       \n",
      " 11  end_lng             99913 non-null   float64       \n",
      " 12  member_casual       100000 non-null  string        \n",
      "dtypes: category(1), datetime64[ns](2), float64(4), string(6)\n",
      "memory usage: 9.3 MB\n",
      "\n",
      "Memory usage by column:\n",
      "Index                     132\n",
      "ride_id               6500000\n",
      "rideable_type          100231\n",
      "started_at             800000\n",
      "ended_at               800000\n",
      "start_station_name    7081717\n",
      "start_station_id      5510377\n",
      "end_station_name      7083099\n",
      "end_station_id        5510515\n",
      "start_lat              800000\n",
      "start_lng              800000\n",
      "end_lat                800000\n",
      "end_lng                800000\n",
      "member_casual         5500000\n",
      "dtype: int64\n",
      "\n",
      "Total memory usage:\n",
      "40.14 MB\n"
     ]
    }
   ],
   "source": [
    "#csv_path = Path('~/INSY6500/my_repo/data/202410-divvy-tripdata-100k.csv',\n",
    "                #dtype={'ride_id': 'string', 'rideable_type': 'category', 'started_at': 'date', 'ended_at': 'date', 'start_station_name': 'string', 'start_station_id': 'string', 'end_station_name': 'string', 'end_station_id': 'string'})\n",
    "\n",
    "#2b.1.\n",
    "rides = pd.read_csv('~/INSY6500/my_repo/data/202410-divvy-tripdata-100k.csv',\n",
    "                dtype={'ride_id': 'string', 'rideable_type': 'category', 'start_station_name': 'string', 'start_station_id': 'string', 'end_station_name': 'string', 'end_station_id': 'string', 'member_casual': 'string'},\n",
    "                parse_dates = ['started_at', 'ended_at'])\n",
    "#rides changes the dytpe of specific indexs to another dytpe\n",
    "\n",
    "#2b.2.\n",
    "rides.info() #General info about the data structure\n",
    "\n",
    "#2b.3.\n",
    "print(\"\\nMemory usage by column:\")\n",
    "print(rides.memory_usage(deep=True)) #Use memory_usage() for detailed breakdown of memory usage by index\n",
    "\n",
    "print(\"\\nTotal memory usage:\")\n",
    "print(f\"{rides.memory_usage(deep=True).sum() / 1024**2:.2f} MB\") #Sums up total memory used by entire DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "#### Task 2c: Explore Structure and Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "Using the `rides` DataFrame from Task 2b:\n",
    "\n",
    "1. Determine the range of starting dates in the dataframe using the `min` and `max` methods.\n",
    "2. Count the number of missing values in each column. See the section of the same name in lecture 06b.\n",
    "3. Convert the Series from step 2 to a DataFrame using `.to_frame(name='count')`, then add a column called 'percentage' that calculates the percentage of missing values for each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Date: 2024-09-30\n",
      "Maximum Date: 2024-09-30\n",
      "\n",
      "Missing Values Data:\n",
      "ride_id                   0\n",
      "rideable_type             0\n",
      "started_at                0\n",
      "ended_at                  0\n",
      "start_station_name    10377\n",
      "start_station_id      10377\n",
      "end_station_name      10515\n",
      "end_station_id        10515\n",
      "start_lat                 0\n",
      "start_lng                 0\n",
      "end_lat                  87\n",
      "end_lng                  87\n",
      "member_casual             0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>percentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ride_id</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rideable_type</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started_at</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ended_at</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_name</th>\n",
       "      <td>10377</td>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_station_id</th>\n",
       "      <td>10377</td>\n",
       "      <td>10.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_station_name</th>\n",
       "      <td>10515</td>\n",
       "      <td>10.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_station_id</th>\n",
       "      <td>10515</td>\n",
       "      <td>10.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lat</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>start_lng</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lat</th>\n",
       "      <td>87</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end_lng</th>\n",
       "      <td>87</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>member_casual</th>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count  percentage\n",
       "ride_id                 0        0.00\n",
       "rideable_type           0        0.00\n",
       "started_at              0        0.00\n",
       "ended_at                0        0.00\n",
       "start_station_name  10377       10.38\n",
       "start_station_id    10377       10.38\n",
       "end_station_name    10515       10.51\n",
       "end_station_id      10515       10.51\n",
       "start_lat               0        0.00\n",
       "start_lng               0        0.00\n",
       "end_lat                87        0.09\n",
       "end_lng                87        0.09\n",
       "member_casual           0        0.00"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 2c code here...\n",
    "\n",
    "#2c. 1.\n",
    "min_date = rides[\"started_at\"].min().date() #Finding the minimum date in the range\n",
    "max_date = rides[\"started_at\"].min().date() #Finding the maximum data in the range\n",
    "\n",
    "print(\"Minimum Date:\", min_date)\n",
    "print(\"Maximum Date:\", max_date)\n",
    "\n",
    "#2c. 2.\n",
    "missing_data = rides.isna().sum() #Counting the number of missing values in each column\n",
    "print(\"\\nMissing Values Data:\")\n",
    "print(missing_data)\n",
    "\n",
    "#2c. 3.\n",
    "df_2 = missing_data.to_frame(name='count') #Converting series to DataFrame\n",
    "#df_2[\"percentage\"] = (df_2 / df_2.sum())*100 #Arithmetic operations to calculate the percentage of missing values for each column\n",
    "df_2[\"percentage\"] = (df_2[\"count\"] / len(rides))*100\n",
    "df_2.round(2) #rounding result to 2 decimal places\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45",
   "metadata": {},
   "source": [
    "#### Task 2d: Create Trip Duration Column and Set Index\n",
    "\n",
    "Before setting the index, create a derived column for trip duration:\n",
    "\n",
    "1. Calculate trip_duration_min by subtracting `started_at` from `ended_at`, then converting to minutes using `.dt.total_seconds() / 60`\n",
    "3. Display basic statistics (min, max, mean) for the new column using `.describe()`\n",
    "4. Show the first few rows with `started_at`, `ended_at`, and `trip_duration_min` to verify the calculation\n",
    "5. Set `started_at` as the DataFrame's index. Verify the change by printing the index and displaying the first few rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic Statistics:\n",
      "count    100000.00\n",
      "mean         16.14\n",
      "std          52.92\n",
      "min           0.01\n",
      "25%           5.49\n",
      "50%           9.42\n",
      "75%          16.41\n",
      "max        1499.95\n",
      "Name: Duration, dtype: float64\n",
      "               started_at                ended_at   Duration\n",
      "0 2024-09-30 23:12:01.622 2024-10-01 00:20:00.674  67.984200\n",
      "1 2024-09-30 23:19:25.409 2024-10-01 00:42:09.933  82.742067\n",
      "2 2024-09-30 23:32:24.672 2024-10-01 00:23:18.647  50.899583\n",
      "3 2024-09-30 23:42:11.207 2024-10-01 00:10:16.831  28.093733\n",
      "4 2024-09-30 23:49:25.380 2024-10-01 00:06:27.476  17.034933\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>Duration</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>started_at</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2024-09-30 23:12:01.622</th>\n",
       "      <td>67BB74BD7667BAB7</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-10-01 00:20:00.674</td>\n",
       "      <td>Oakley Ave &amp; Touhy Ave</td>\n",
       "      <td>bdd4c3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>42.012342</td>\n",
       "      <td>-87.688243</td>\n",
       "      <td>41.970000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>casual</td>\n",
       "      <td>67.984200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 23:19:25.409</th>\n",
       "      <td>5AF1AC3BA86ED58C</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-10-01 00:42:09.933</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Benson Ave &amp; Church St</td>\n",
       "      <td>a10cf0</td>\n",
       "      <td>42.070000</td>\n",
       "      <td>-87.730000</td>\n",
       "      <td>42.048214</td>\n",
       "      <td>-87.683485</td>\n",
       "      <td>casual</td>\n",
       "      <td>82.742067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 23:32:24.672</th>\n",
       "      <td>7961DD2FC1280CDC</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-01 00:23:18.647</td>\n",
       "      <td>St. Clair St &amp; Erie St</td>\n",
       "      <td>9c619a</td>\n",
       "      <td>LaSalle St &amp; Illinois St</td>\n",
       "      <td>fbd1ad</td>\n",
       "      <td>41.894345</td>\n",
       "      <td>-87.622798</td>\n",
       "      <td>41.890762</td>\n",
       "      <td>-87.631697</td>\n",
       "      <td>member</td>\n",
       "      <td>50.899583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 23:42:11.207</th>\n",
       "      <td>2E16892DEEF4CC19</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-01 00:10:16.831</td>\n",
       "      <td>Ashland Ave &amp; Chicago Ave</td>\n",
       "      <td>72a04d</td>\n",
       "      <td>Loomis St &amp; Archer Ave</td>\n",
       "      <td>896337</td>\n",
       "      <td>41.895954</td>\n",
       "      <td>-87.667728</td>\n",
       "      <td>41.841633</td>\n",
       "      <td>-87.657435</td>\n",
       "      <td>casual</td>\n",
       "      <td>28.093733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-09-30 23:49:25.380</th>\n",
       "      <td>AAF0220F819BEE01</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-10-01 00:06:27.476</td>\n",
       "      <td>900 W Harrison St</td>\n",
       "      <td>11da85</td>\n",
       "      <td>900 W Harrison St</td>\n",
       "      <td>11da85</td>\n",
       "      <td>41.874754</td>\n",
       "      <td>-87.649807</td>\n",
       "      <td>41.874754</td>\n",
       "      <td>-87.649807</td>\n",
       "      <td>member</td>\n",
       "      <td>17.034933</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  ride_id  rideable_type  \\\n",
       "started_at                                                 \n",
       "2024-09-30 23:12:01.622  67BB74BD7667BAB7  electric_bike   \n",
       "2024-09-30 23:19:25.409  5AF1AC3BA86ED58C  electric_bike   \n",
       "2024-09-30 23:32:24.672  7961DD2FC1280CDC   classic_bike   \n",
       "2024-09-30 23:42:11.207  2E16892DEEF4CC19   classic_bike   \n",
       "2024-09-30 23:49:25.380  AAF0220F819BEE01  electric_bike   \n",
       "\n",
       "                                       ended_at         start_station_name  \\\n",
       "started_at                                                                   \n",
       "2024-09-30 23:12:01.622 2024-10-01 00:20:00.674     Oakley Ave & Touhy Ave   \n",
       "2024-09-30 23:19:25.409 2024-10-01 00:42:09.933                       <NA>   \n",
       "2024-09-30 23:32:24.672 2024-10-01 00:23:18.647     St. Clair St & Erie St   \n",
       "2024-09-30 23:42:11.207 2024-10-01 00:10:16.831  Ashland Ave & Chicago Ave   \n",
       "2024-09-30 23:49:25.380 2024-10-01 00:06:27.476          900 W Harrison St   \n",
       "\n",
       "                        start_station_id          end_station_name  \\\n",
       "started_at                                                           \n",
       "2024-09-30 23:12:01.622           bdd4c3                      <NA>   \n",
       "2024-09-30 23:19:25.409             <NA>    Benson Ave & Church St   \n",
       "2024-09-30 23:32:24.672           9c619a  LaSalle St & Illinois St   \n",
       "2024-09-30 23:42:11.207           72a04d    Loomis St & Archer Ave   \n",
       "2024-09-30 23:49:25.380           11da85         900 W Harrison St   \n",
       "\n",
       "                        end_station_id  start_lat  start_lng    end_lat  \\\n",
       "started_at                                                                \n",
       "2024-09-30 23:12:01.622           <NA>  42.012342 -87.688243  41.970000   \n",
       "2024-09-30 23:19:25.409         a10cf0  42.070000 -87.730000  42.048214   \n",
       "2024-09-30 23:32:24.672         fbd1ad  41.894345 -87.622798  41.890762   \n",
       "2024-09-30 23:42:11.207         896337  41.895954 -87.667728  41.841633   \n",
       "2024-09-30 23:49:25.380         11da85  41.874754 -87.649807  41.874754   \n",
       "\n",
       "                           end_lng member_casual   Duration  \n",
       "started_at                                                   \n",
       "2024-09-30 23:12:01.622 -87.650000        casual  67.984200  \n",
       "2024-09-30 23:19:25.409 -87.683485        casual  82.742067  \n",
       "2024-09-30 23:32:24.672 -87.631697        member  50.899583  \n",
       "2024-09-30 23:42:11.207 -87.657435        casual  28.093733  \n",
       "2024-09-30 23:49:25.380 -87.649807        member  17.034933  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# task 2d code here...\n",
    "\n",
    "#2d. 1.\n",
    "rides['Duration'] = (rides['ended_at'] - rides['started_at']).dt.total_seconds() / 60 #Creating a new column called Duration and running th calcuation for insert into the data frame\n",
    "\n",
    "#2d. 2.\n",
    "print(\"Basic Statistics:\")\n",
    "print(rides['Duration'].describe().round(2)) #Display basic statistics for new Duration column\n",
    "\n",
    "#2d. 3.\n",
    "rides_head = rides[['started_at', 'ended_at', 'Duration']].head() #Show first few rows with specific index headers\n",
    "print(rides_head)\n",
    "\n",
    "#2d. 4.\n",
    "rides = rides.set_index('started_at') #Set index to started times\n",
    "rides.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49",
   "metadata": {},
   "source": [
    "Reflect on problem 2 and answer (briefly / concisely) the following questions:\n",
    "\n",
    "1. What types did Pandas assign to `started_at` and `member_casual` in Task 2a? Why might these defaults be problematic?\n",
    "2. Look at the values in the station ID fields. Based on what you learned about git commit IDs in HW3a, how do you think the station IDs were derived?\n",
    "3. Explain in your own words what method chaining is, what `df.isna().sum()` does and how it works.\n",
    "4. Assume you found ~10% missing values in station columns but ~0% in coordinates. What might explain this? How might you handle the affected rows?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "##### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51",
   "metadata": {},
   "source": [
    "*Problem 2 interpretation here*\n",
    "1. started_at and member_casual were assigned types, 'object'. These could be problematic because it makes indexing and sorting more difficult due to the lack of unique characteristic of being a cateogry, datetime, float, etc.\n",
    "\n",
    "2. dsfsdfsd\n",
    "\n",
    "3. Method chaining is essential taking multiple methods and stringing them together to form one line command which accomplish multiples commands at once. Instead of having to write multiple lines of code to accomplish each command, you can chain methods togather in one line. df.isna().sum() creates an array of boolean values, where true = 1 and false = 0. This is applied to every value in the DataFrame which is then, by use of method chaining, sums the total.\n",
    "\n",
    "4.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54",
   "metadata": {},
   "source": [
    "##### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "#### Follow-Up (Graduate Students Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55",
   "metadata": {},
   "source": [
    "*Problem 2 follow-up response here*\n",
    "The reason why the memory usage for 2b.3. is significantly higher than 2a.3. is because we changed a lot of the dtypes to strings which often represent categorical data. Strings in general can take up significant amounts of memory. In situations where a dtype of category can be used, it could save significant amounts of memory. It's different because memory_usage() method helps to identify which columns consume the most memory so it gives you a more detailed look at how memory each dtype is taking up, whereas df.info() just gives you general information about the data structure.\n",
    "\n",
    "For the optimistic case (5x), the max dataset size would have to be 2.24 GB. For the conservative case (10x), the max dataset size would be 1.12 GB. You could be somewhere in the middle but conservative is always a good option because it gives you wiggle room for experimenting, making copies, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### Problem 3: Filtering and Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57",
   "metadata": {},
   "source": [
    "With clean data loaded, you can now filter and transform it to answer specific questions. This problem focuses on Pandas' powerful indexing and filtering capabilities, along with creating derived columns that enable deeper analysis.\n",
    "\n",
    "You'll continue working with the `rides` DataFrame from Problem 2, which has `started_at` set as the index."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "58",
   "metadata": {},
   "source": [
    "#### Task 3a: Boolean Indexing and Membership Testing\n",
    "\n",
    "Use boolean indexing and the `isin()` method to answer these questions:\n",
    "\n",
    "1. How many trips were taken by *members* using *electric bikes*? Use `&` to combine conditions.\n",
    "2. What percentage of all trips does this represent?\n",
    "3. How many trips started at any of these three stations: \"Streeter Dr & Grand Ave\", \"DuSable Lake Shore Dr & Monroe St\", or \"Kingsbury St & Kinzie St\"? Use `isin()`.\n",
    "\n",
    "Note: Remember to use parentheses around each condition when combining with `&`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Member Trips Using Electric Bikes:\n",
      "33121\n",
      "\n",
      "Percentage of All Trips Where Members Used Electric Bikes:\n",
      "33.1%\n",
      "\n",
      "Trips Starting at Streeter & Grand Ave, DuSable Lake Shore Dr & Monroe St, and Kingsbury St & Kinizie St\n",
      "809\n"
     ]
    }
   ],
   "source": [
    "# Task 3a code here...\n",
    "#3a. 1.\n",
    "electric = rides[(rides['rideable_type'] == 'electric_bike') & (rides['member_casual'] == 'member')]\n",
    "print(\"Member Trips Using Electric Bikes:\")\n",
    "print(len(electric))\n",
    "\n",
    "#3a. 2.\n",
    "percent = (len(electric) / len(rides))*100\n",
    "print(\"\\nPercentage of All Trips Where Members Used Electric Bikes:\")\n",
    "print(f\"{percent:.1f}%\")\n",
    "\n",
    "#3a. 3.\n",
    "start_station = rides[rides['start_station_name'].isin(['Street Dr & Grand Ave', 'DuSable Lake Shore Dr & Monroe St', 'Kingsbury St & Kinizie St'])]\n",
    "print(\"\\nTrips Starting at Streeter & Grand Ave, DuSable Lake Shore Dr & Monroe St, and Kingsbury St & Kinizie St\")\n",
    "print(len(start_station))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61",
   "metadata": {},
   "source": [
    "#### Task 3b: Create Derived Columns from Datetime\n",
    "\n",
    "Add two categorical columns to the rides DataFrame based on trip start time:\n",
    "\n",
    "1. `is_weekend`: Boolean column that is True for Saturday/Sunday trips. Use .dt.dayofweek on the index (Monday=0, Sunday=6).\n",
    "2. `time_of_day`: String categories based on start hour:\n",
    "   - \"Morning Rush\" if hour is 7, 8, or 9\n",
    "   - \"Evening Rush\" if hour is 16, 17, or 18\n",
    "   - \"Midday\" for all other hours\n",
    "\n",
    "For step 2, initialize the column to \"Midday\", then use .loc[mask, 'time_of_day'] with boolean masks to assign rush hour categories. Extract hour using .dt.hour on the index.\n",
    "\n",
    "After creating both columns, use value_counts() on time_of_day to show the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time_of_day\n",
      "Midday          55326\n",
      "Evening Rush    28808\n",
      "Morning Rush    15866\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 3b code here...\n",
    "rides = rides.reset_index()\n",
    "rides['is_weekend'] = rides['started_at'].dt.dayofweek >= 5\n",
    "rides[\"time_of_day\"] = \"Midday\"\n",
    "Morning_Rush = rides['started_at'].dt.hour.isin([7, 8, 9])\n",
    "Evening_Rush = rides['ended_at'].dt.hour.isin([16, 17, 18])\n",
    "rides.loc[Morning_Rush,'time_of_day'] = \"Morning Rush\"\n",
    "rides.loc[Evening_Rush, 'time_of_day'] = \"Evening Rush\"\n",
    "print(rides['time_of_day'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "#### Task 3c: Complex Filtering with query()\n",
    "\n",
    "Use the `query()` method to find trips that meet **all** of these criteria:\n",
    "- Casual riders (not members)\n",
    "- Weekend trips  \n",
    "- Duration greater than 20 minutes\n",
    "- Electric bikes\n",
    "\n",
    "Report:\n",
    "1. How many trips match these criteria?\n",
    "2. What percentage of all trips do they represent?\n",
    "3. What is the average duration of these trips?\n",
    "\n",
    "Hint: Column names work directly in `query()` strings. Combine conditions with `and`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many trips match the critiera?\n",
      "1501\n",
      "\n",
      "What percentage of all trips do they represent?\n",
      "1.5%\n",
      "\n",
      "What is the average duration of these trips?\n",
      "40.37 minutes\n"
     ]
    }
   ],
   "source": [
    "# Task 3c code here...\n",
    "rides\n",
    "result = rides.query('member_casual == \"casual\" and is_weekend == True and Duration > 20 and rideable_type == \"electric_bike\"')\n",
    "print(\"How many trips match the critiera?\")\n",
    "print(len(result))\n",
    "percent_3c = (len(result) / len(rides))*100\n",
    "print(\"\\nWhat percentage of all trips do they represent?\")\n",
    "print(f\"{percent_3c:.1f}%\")\n",
    "average_dur = result['Duration'].mean()\n",
    "print(\"\\nWhat is the average duration of these trips?\")\n",
    "print(f\"{average_dur:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67",
   "metadata": {},
   "source": [
    "#### Task 3d: Explicit Indexing Practice\n",
    "\n",
    "Practice using `loc[]` and `iloc[]` for different selection tasks:\n",
    "\n",
    "1. Use `iloc[]` to select the first 10 trips, showing only `member_casual`, `rideable_type`, and `trip_duration_min` columns\n",
    "2. Use `loc[]` to select trips from October 15-17 (use date strings `'2024-10-15':'2024-10-17'`), showing the same three columns\n",
    "3. Count how many trips occurred during this date range\n",
    "\n",
    "Note: When using `iloc[]`, remember it's position-based (0-indexed). When using `loc[]` with the datetime index, you can slice using date strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    67BB74BD7667BAB7\n",
      "1    5AF1AC3BA86ED58C\n",
      "2    7961DD2FC1280CDC\n",
      "3    2E16892DEEF4CC19\n",
      "4    AAF0220F819BEE01\n",
      "5    FB4613BAA257ECD7\n",
      "6    7815EF87568C4CCC\n",
      "7    D3DCEFD88F5A118D\n",
      "8    2CF8741A5C9A501E\n",
      "9    A1893A2CAEC7C9E3\n",
      "Name: ride_id, dtype: string\n"
     ]
    }
   ],
   "source": [
    "# Task 3d code here...\n",
    "first_ten = rides.iloc[:10, 0]\n",
    "print(first_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70",
   "metadata": {},
   "source": [
    "#### Interpretation\n",
    "\n",
    "Reflect on this problem and answer (briefly / concisely) the following questions:\n",
    "\n",
    "1. `isin()` advantages: Compare using `isin(['A', 'B', 'C'])` versus `(col == 'A') | (col == 'B') | (col == 'C')`. Beyond readability, what practical advantage does `isin()` provide when filtering for many values (e.g., 20+ stations)?\n",
    "2. Conditional assignment order: In Task 3b, why did we initialize all values to \"Midday\" before assigning rush hour categories? What would go wrong if you assigned categories in a different order, or didn't set a default?\n",
    "3. `query()` vs boolean indexing: The `query()` method in Task 3c could have been written with boolean indexing instead. When would you choose `query()` over boolean indexing? When might boolean indexing be preferable despite being more verbose?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71",
   "metadata": {},
   "source": [
    "##### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72",
   "metadata": {},
   "source": [
    "*Problem 3 interpretation here*\n",
    "1. .isin() is vectorized and is able to accept a list variable. This keeps from having to write out long chains like ones where the pipe symbol or ampersand symbol are used. Beyond readability, the code is cleaner, less error prone, and performs much faster since it's vectorized. When you use .isin() the evaluation occurs at each element. \n",
    "\n",
    "2. We initialized to \"Midday\" because it made it easier to establish the addition of the column and the data so that we could then go in and create masks to then set the correct condition based on the time hour.\n",
    "\n",
    "3. .query() is able to handle more complex filters that invlove multiple parameters. You can also use in conjunction with method chaining which reduces the amount of code and it's less error prone. Boolean indexing on the other hand is more explicit but adaptable or flexible, meaning it can be used in any situation, although I guess compared to .query() it's more clunky, but it just won't operate as efficient as .query(). Use boolean indexing if you want to be more simple and get the job done, maybe you need just one parameter and not multiple. It can also be easier to see issues in the results for each, but it's also suceptible to being more difficult to follow for situations with multiple parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73",
   "metadata": {},
   "source": [
    "#### Follow-Up (Graduate Students Only)\n",
    "\n",
    "Pandas supports a variety of indexing paradigms, including bracket notation (`df['col']`), label-based indexing (`loc[]`), and position-based indexing (`iloc[]`). The lecture recommended using bracket notation only for columns, and loc/iloc for everything else. Explain the rationale: why is this approach better than using bracket notation for everything, even though `df[0:5]` technically works for row slicing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74",
   "metadata": {},
   "source": [
    "##### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "*Graduate follow-up interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76",
   "metadata": {},
   "source": [
    "### Problem 4: Temporal Analysis and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77",
   "metadata": {},
   "source": [
    "Time-based patterns are crucial for understanding bike share usage. In this problem, you'll analyze when trips occur, how usage differs between rider types, and export filtered results. You'll use the datetime index you set in Problem 2 and the derived columns from Problems 2-3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78",
   "metadata": {},
   "source": [
    "#### Task 4a: Identify Temporal Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "Use the datetime index to extract temporal components and identify usage patterns:\n",
    "\n",
    "1. Extract the *hour* from the index and use `value_counts()` to find the most popular hour for trips. Report the peak hour and how many trips occurred during that hour.\n",
    "2. Extract the *day name* from the index and use `value_counts()` to find the busiest day of the week. Report the day and number of trips.\n",
    "3. Sort the results from step 2 to show days in order from Monday to Sunday (not by trip count). Use `sort_index()`.\n",
    "\n",
    "Hint: Use `.dt.hour` and `.dt.day_name()` on the datetime index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Hour:\n",
      "17\n",
      "\n",
      "Peak Hour Trips:\n",
      "10574\n",
      "\n",
      "Busiest Day:\n",
      "Wednesday\n",
      "\n",
      "Busiest Day Trips:\n",
      "16513\n",
      "\n",
      "Trips By Day of The Week:\n",
      "Monday       11531\n",
      "Tuesday      14970\n",
      "Wednesday    16513\n",
      "Thursday     16080\n",
      "Friday       13691\n",
      "Saturday     14427\n",
      "Sunday       12788\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 4a code here...\n",
    "#4a. 1.\n",
    "rides_start = rides_start.reset_index('started_at')\n",
    "instances = rides_start['started_at'].dt.hour.value_counts()\n",
    "popular_hr = instances.idxmax()\n",
    "popular_hr_ocr = instances.max()\n",
    "print(\"Peak Hour:\")\n",
    "print(popular_hr)\n",
    "print(\"\\nPeak Hour Trips:\")\n",
    "print(popular_hr_ocr)\n",
    "#rides_start.index.dt.hour.value_counts()\n",
    "\n",
    "#4a. 2.\n",
    "day = rides_start['started_at'].dt.day_name().value_counts()\n",
    "popular_day = day.idxmax()\n",
    "popular_day_ocr = day.max()\n",
    "print(\"\\nBusiest Day:\")\n",
    "print(popular_day)\n",
    "print(\"\\nBusiest Day Trips:\")\n",
    "print(popular_day_ocr)\n",
    "\n",
    "#4a. 3.\n",
    "\n",
    "day_of_week = rides_start['started_at'].dt.dayofweek.value_counts().sort_index()\n",
    "day_of_week.index = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "print(\"\\nTrips By Day of The Week:\")\n",
    "print(day_of_week)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82",
   "metadata": {},
   "source": [
    "#### Task 4b: Compare Groups with groupby()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83",
   "metadata": {},
   "source": [
    "Use `groupby()` (introduced in 07a) to compare trip characteristics across different groups:\n",
    "\n",
    "1. Calculate the average trip duration by rider type (`member_casual`). Which group takes longer trips on average?\n",
    "2. Calculate the average trip duration by bike type (`rideable_type`). Which bike type has the longest average trip?\n",
    "3. Count the number of trips by rider type using `groupby()` with `.size()`. Compare this with using `value_counts()` on the `member_casual` column - do they give the same result?\n",
    "\n",
    "Note: Use single-key groupby only (one column at a time)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Which group takes longer trips on average?\n",
      "casual\n",
      "\n",
      "Which bike has the longest average trip?\n",
      "classic_bike\n",
      "\n",
      "Section 4b. 3.\n",
      "rideable_type\n",
      "classic_bike     49507\n",
      "electric_bike    50493\n",
      "Name: Duration, dtype: int64\n",
      "rideable_type\n",
      "electric_bike    50493\n",
      "classic_bike     49507\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Do they give the same reuslt?\n",
      "Yes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ride_id</th>\n",
       "      <th>rideable_type</th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lng</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lng</th>\n",
       "      <th>member_casual</th>\n",
       "      <th>Duration</th>\n",
       "      <th>is_weekend</th>\n",
       "      <th>time_of_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67BB74BD7667BAB7</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-09-30 23:12:01.622</td>\n",
       "      <td>2024-10-01 00:20:00.674</td>\n",
       "      <td>Oakley Ave &amp; Touhy Ave</td>\n",
       "      <td>bdd4c3</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>42.012342</td>\n",
       "      <td>-87.688243</td>\n",
       "      <td>41.970000</td>\n",
       "      <td>-87.650000</td>\n",
       "      <td>casual</td>\n",
       "      <td>67.984200</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5AF1AC3BA86ED58C</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-09-30 23:19:25.409</td>\n",
       "      <td>2024-10-01 00:42:09.933</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>Benson Ave &amp; Church St</td>\n",
       "      <td>a10cf0</td>\n",
       "      <td>42.070000</td>\n",
       "      <td>-87.730000</td>\n",
       "      <td>42.048214</td>\n",
       "      <td>-87.683485</td>\n",
       "      <td>casual</td>\n",
       "      <td>82.742067</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7961DD2FC1280CDC</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-09-30 23:32:24.672</td>\n",
       "      <td>2024-10-01 00:23:18.647</td>\n",
       "      <td>St. Clair St &amp; Erie St</td>\n",
       "      <td>9c619a</td>\n",
       "      <td>LaSalle St &amp; Illinois St</td>\n",
       "      <td>fbd1ad</td>\n",
       "      <td>41.894345</td>\n",
       "      <td>-87.622798</td>\n",
       "      <td>41.890762</td>\n",
       "      <td>-87.631697</td>\n",
       "      <td>member</td>\n",
       "      <td>50.899583</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2E16892DEEF4CC19</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-09-30 23:42:11.207</td>\n",
       "      <td>2024-10-01 00:10:16.831</td>\n",
       "      <td>Ashland Ave &amp; Chicago Ave</td>\n",
       "      <td>72a04d</td>\n",
       "      <td>Loomis St &amp; Archer Ave</td>\n",
       "      <td>896337</td>\n",
       "      <td>41.895954</td>\n",
       "      <td>-87.667728</td>\n",
       "      <td>41.841633</td>\n",
       "      <td>-87.657435</td>\n",
       "      <td>casual</td>\n",
       "      <td>28.093733</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAF0220F819BEE01</td>\n",
       "      <td>electric_bike</td>\n",
       "      <td>2024-09-30 23:49:25.380</td>\n",
       "      <td>2024-10-01 00:06:27.476</td>\n",
       "      <td>900 W Harrison St</td>\n",
       "      <td>11da85</td>\n",
       "      <td>900 W Harrison St</td>\n",
       "      <td>11da85</td>\n",
       "      <td>41.874754</td>\n",
       "      <td>-87.649807</td>\n",
       "      <td>41.874754</td>\n",
       "      <td>-87.649807</td>\n",
       "      <td>member</td>\n",
       "      <td>17.034933</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>6D5AFF497514A788</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-31 23:44:23.211</td>\n",
       "      <td>2024-10-31 23:49:31.022</td>\n",
       "      <td>Wells St &amp; Evergreen Ave</td>\n",
       "      <td>904fde</td>\n",
       "      <td>Wells St &amp; Institute Pl</td>\n",
       "      <td>ef812f</td>\n",
       "      <td>41.906724</td>\n",
       "      <td>-87.634830</td>\n",
       "      <td>41.897380</td>\n",
       "      <td>-87.634420</td>\n",
       "      <td>casual</td>\n",
       "      <td>5.130183</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>527E9D2BDCAFFEC4</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-31 23:44:45.948</td>\n",
       "      <td>2024-10-31 23:50:47.698</td>\n",
       "      <td>Clark St &amp; Newport St</td>\n",
       "      <td>1f2cb8</td>\n",
       "      <td>Southport Ave &amp; Waveland Ave</td>\n",
       "      <td>9611f6</td>\n",
       "      <td>41.944540</td>\n",
       "      <td>-87.654678</td>\n",
       "      <td>41.948226</td>\n",
       "      <td>-87.664071</td>\n",
       "      <td>member</td>\n",
       "      <td>6.029167</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>33A63439F82E7542</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-31 23:50:31.160</td>\n",
       "      <td>2024-10-31 23:55:44.488</td>\n",
       "      <td>Damen Ave &amp; Charleston St</td>\n",
       "      <td>929cd0</td>\n",
       "      <td>Damen Ave &amp; Pierce Ave</td>\n",
       "      <td>fbf054</td>\n",
       "      <td>41.920082</td>\n",
       "      <td>-87.677855</td>\n",
       "      <td>41.909396</td>\n",
       "      <td>-87.677692</td>\n",
       "      <td>casual</td>\n",
       "      <td>5.222133</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>2BE6AF69988C197F</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-31 23:53:02.355</td>\n",
       "      <td>2024-10-31 23:58:27.675</td>\n",
       "      <td>Lincoln Ave &amp; Roscoe St*</td>\n",
       "      <td>a2de82</td>\n",
       "      <td>Leavitt St &amp; Belmont Ave</td>\n",
       "      <td>a7b478</td>\n",
       "      <td>41.943350</td>\n",
       "      <td>-87.670668</td>\n",
       "      <td>41.939354</td>\n",
       "      <td>-87.683282</td>\n",
       "      <td>member</td>\n",
       "      <td>5.422000</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>A925983EBD0E911E</td>\n",
       "      <td>classic_bike</td>\n",
       "      <td>2024-10-31 23:54:02.851</td>\n",
       "      <td>2024-10-31 23:57:44.279</td>\n",
       "      <td>State St &amp; Harrison St</td>\n",
       "      <td>f4980a</td>\n",
       "      <td>Financial Pl &amp; Ida B Wells Dr</td>\n",
       "      <td>9cda45</td>\n",
       "      <td>41.874053</td>\n",
       "      <td>-87.627716</td>\n",
       "      <td>41.875024</td>\n",
       "      <td>-87.633094</td>\n",
       "      <td>member</td>\n",
       "      <td>3.690467</td>\n",
       "      <td>False</td>\n",
       "      <td>Midday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ride_id  rideable_type              started_at  \\\n",
       "0      67BB74BD7667BAB7  electric_bike 2024-09-30 23:12:01.622   \n",
       "1      5AF1AC3BA86ED58C  electric_bike 2024-09-30 23:19:25.409   \n",
       "2      7961DD2FC1280CDC   classic_bike 2024-09-30 23:32:24.672   \n",
       "3      2E16892DEEF4CC19   classic_bike 2024-09-30 23:42:11.207   \n",
       "4      AAF0220F819BEE01  electric_bike 2024-09-30 23:49:25.380   \n",
       "...                 ...            ...                     ...   \n",
       "99995  6D5AFF497514A788   classic_bike 2024-10-31 23:44:23.211   \n",
       "99996  527E9D2BDCAFFEC4   classic_bike 2024-10-31 23:44:45.948   \n",
       "99997  33A63439F82E7542   classic_bike 2024-10-31 23:50:31.160   \n",
       "99998  2BE6AF69988C197F   classic_bike 2024-10-31 23:53:02.355   \n",
       "99999  A925983EBD0E911E   classic_bike 2024-10-31 23:54:02.851   \n",
       "\n",
       "                     ended_at         start_station_name start_station_id  \\\n",
       "0     2024-10-01 00:20:00.674     Oakley Ave & Touhy Ave           bdd4c3   \n",
       "1     2024-10-01 00:42:09.933                       <NA>             <NA>   \n",
       "2     2024-10-01 00:23:18.647     St. Clair St & Erie St           9c619a   \n",
       "3     2024-10-01 00:10:16.831  Ashland Ave & Chicago Ave           72a04d   \n",
       "4     2024-10-01 00:06:27.476          900 W Harrison St           11da85   \n",
       "...                       ...                        ...              ...   \n",
       "99995 2024-10-31 23:49:31.022   Wells St & Evergreen Ave           904fde   \n",
       "99996 2024-10-31 23:50:47.698      Clark St & Newport St           1f2cb8   \n",
       "99997 2024-10-31 23:55:44.488  Damen Ave & Charleston St           929cd0   \n",
       "99998 2024-10-31 23:58:27.675   Lincoln Ave & Roscoe St*           a2de82   \n",
       "99999 2024-10-31 23:57:44.279     State St & Harrison St           f4980a   \n",
       "\n",
       "                    end_station_name end_station_id  start_lat  start_lng  \\\n",
       "0                               <NA>           <NA>  42.012342 -87.688243   \n",
       "1             Benson Ave & Church St         a10cf0  42.070000 -87.730000   \n",
       "2           LaSalle St & Illinois St         fbd1ad  41.894345 -87.622798   \n",
       "3             Loomis St & Archer Ave         896337  41.895954 -87.667728   \n",
       "4                  900 W Harrison St         11da85  41.874754 -87.649807   \n",
       "...                              ...            ...        ...        ...   \n",
       "99995        Wells St & Institute Pl         ef812f  41.906724 -87.634830   \n",
       "99996   Southport Ave & Waveland Ave         9611f6  41.944540 -87.654678   \n",
       "99997         Damen Ave & Pierce Ave         fbf054  41.920082 -87.677855   \n",
       "99998       Leavitt St & Belmont Ave         a7b478  41.943350 -87.670668   \n",
       "99999  Financial Pl & Ida B Wells Dr         9cda45  41.874053 -87.627716   \n",
       "\n",
       "         end_lat    end_lng member_casual   Duration  is_weekend time_of_day  \n",
       "0      41.970000 -87.650000        casual  67.984200       False      Midday  \n",
       "1      42.048214 -87.683485        casual  82.742067       False      Midday  \n",
       "2      41.890762 -87.631697        member  50.899583       False      Midday  \n",
       "3      41.841633 -87.657435        casual  28.093733       False      Midday  \n",
       "4      41.874754 -87.649807        member  17.034933       False      Midday  \n",
       "...          ...        ...           ...        ...         ...         ...  \n",
       "99995  41.897380 -87.634420        casual   5.130183       False      Midday  \n",
       "99996  41.948226 -87.664071        member   6.029167       False      Midday  \n",
       "99997  41.909396 -87.677692        casual   5.222133       False      Midday  \n",
       "99998  41.939354 -87.683282        member   5.422000       False      Midday  \n",
       "99999  41.875024 -87.633094        member   3.690467       False      Midday  \n",
       "\n",
       "[100000 rows x 16 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 4b code here...\n",
    "a = rides.groupby('member_casual')['Duration'].mean()\n",
    "print(\"Which group takes longer trips on average?\")\n",
    "print(a.idxmax())\n",
    "b = rides.groupby('rideable_type', observed=True)['Duration'].mean()\n",
    "print(\"\\nWhich bike has the longest average trip?\")\n",
    "print(b.idxmax())\n",
    "\n",
    "print(\"\\nSection 4b. 3.\")\n",
    "c = rides.groupby('rideable_type', observed=True)['Duration'].size()\n",
    "print(c)\n",
    "d = rides['rideable_type'].value_counts()\n",
    "print(d)\n",
    "print(\"\\nDo they give the same reuslt?\")\n",
    "print(\"Yes\")\n",
    "\n",
    "rides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86",
   "metadata": {},
   "source": [
    "#### Task 4c: Filter, Sample, and Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87",
   "metadata": {},
   "source": [
    "Create a filtered dataset for weekend electric bike trips and export it:\n",
    "\n",
    "The provided code once again uses Path to create an `output` directory and constructs the full file path as `output/weekend_electric_trips.csv`. Use the `output_file` variable when calling `.to_csv()`.\n",
    "\n",
    "1. Filter for trips where `is_weekend == True` and `rideable_type == 'electric_bike'`\n",
    "2. Use `iloc[]` to select the first 1000 trips from this filtered dataset\n",
    "3. Use `reset_index()` to convert the datetime index back to a column (so it's included in the export)\n",
    "4. Export to CSV with filename `weekend_electric_trips.csv`, including only these columns: `started_at`, `ended_at`, `member_casual`, `trip_duration_min`, `time_of_day`\n",
    "5. Use `index=False` to avoid writing the default numeric index to the file\n",
    "\n",
    "After exporting, report how many total weekend electric bike trips existed before sampling to 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88",
   "metadata": {},
   "source": [
    "##### Your Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "89",
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefinedVariableError",
     "evalue": "name 'is_weekend' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/scope.py:231\u001b[39m, in \u001b[36mScope.resolve\u001b[39m\u001b[34m(self, key, is_local)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.has_resolvers:\n\u001b[32m--> \u001b[39m\u001b[32m231\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.resolvers[key]\n\u001b[32m    233\u001b[39m \u001b[38;5;66;03m# if we're here that means that we have no locals and we also have\u001b[39;00m\n\u001b[32m    234\u001b[39m \u001b[38;5;66;03m# no resolvers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/collections/__init__.py:1019\u001b[39m, in \u001b[36mChainMap.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1018\u001b[39m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1019\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__missing__\u001b[39m(key)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/collections/__init__.py:1011\u001b[39m, in \u001b[36mChainMap.__missing__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1010\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__missing__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[32m-> \u001b[39m\u001b[32m1011\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'is_weekend'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/scope.py:242\u001b[39m, in \u001b[36mScope.resolve\u001b[39m\u001b[34m(self, key, is_local)\u001b[39m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# last ditch effort we look in temporaries\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# these are created when parsing indexing expressions\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# e.g., df[df > 0]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.temps[key]\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[31mKeyError\u001b[39m: 'is_weekend'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mUndefinedVariableError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[233]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Task 4c code here...\u001b[39;00m\n\u001b[32m      9\u001b[39m rides\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m wknd_elect = rides_start.query(\u001b[33m'\u001b[39m\u001b[33mis_weekend == True and rideable_type == \u001b[39m\u001b[33m\"\u001b[39m\u001b[33melectric_bike\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/frame.py:4828\u001b[39m, in \u001b[36mDataFrame.query\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4826\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m] = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlevel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0\u001b[39m) + \u001b[32m1\u001b[39m\n\u001b[32m   4827\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4828\u001b[39m res = \u001b[38;5;28mself\u001b[39m.eval(expr, **kwargs)\n\u001b[32m   4830\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   4831\u001b[39m     result = \u001b[38;5;28mself\u001b[39m.loc[res]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/frame.py:4954\u001b[39m, in \u001b[36mDataFrame.eval\u001b[39m\u001b[34m(self, expr, inplace, **kwargs)\u001b[39m\n\u001b[32m   4951\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtarget\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m\n\u001b[32m   4952\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mtuple\u001b[39m(kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mresolvers\u001b[39m\u001b[33m\"\u001b[39m, ())) + resolvers\n\u001b[32m-> \u001b[39m\u001b[32m4954\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _eval(expr, inplace=inplace, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/eval.py:339\u001b[39m, in \u001b[36meval\u001b[39m\u001b[34m(expr, parser, engine, local_dict, global_dict, resolvers, level, target, inplace)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;66;03m# get our (possibly passed-in) scope\u001b[39;00m\n\u001b[32m    331\u001b[39m env = ensure_scope(\n\u001b[32m    332\u001b[39m     level + \u001b[32m1\u001b[39m,\n\u001b[32m    333\u001b[39m     global_dict=global_dict,\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m     target=target,\n\u001b[32m    337\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m339\u001b[39m parsed_expr = Expr(expr, engine=engine, parser=parser, env=env)\n\u001b[32m    341\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m engine == \u001b[33m\"\u001b[39m\u001b[33mnumexpr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    342\u001b[39m     (\n\u001b[32m    343\u001b[39m         is_extension_array_dtype(parsed_expr.terms.return_type)\n\u001b[32m   (...)\u001b[39m\u001b[32m    350\u001b[39m     )\n\u001b[32m    351\u001b[39m ):\n\u001b[32m    352\u001b[39m     warnings.warn(\n\u001b[32m    353\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mEngine has switched to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m'\u001b[39m\u001b[33m because numexpr does not support \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    354\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mextension array dtypes. Please set your engine to python manually.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    355\u001b[39m         \u001b[38;5;167;01mRuntimeWarning\u001b[39;00m,\n\u001b[32m    356\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    357\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:809\u001b[39m, in \u001b[36mExpr.__init__\u001b[39m\u001b[34m(self, expr, engine, parser, env, level)\u001b[39m\n\u001b[32m    807\u001b[39m \u001b[38;5;28mself\u001b[39m.parser = parser\n\u001b[32m    808\u001b[39m \u001b[38;5;28mself\u001b[39m._visitor = PARSERS[parser](\u001b[38;5;28mself\u001b[39m.env, \u001b[38;5;28mself\u001b[39m.engine, \u001b[38;5;28mself\u001b[39m.parser)\n\u001b[32m--> \u001b[39m\u001b[32m809\u001b[39m \u001b[38;5;28mself\u001b[39m.terms = \u001b[38;5;28mself\u001b[39m.parse()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:828\u001b[39m, in \u001b[36mExpr.parse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    824\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mparse\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    825\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[33;03m    Parse an expression.\u001b[39;00m\n\u001b[32m    827\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m828\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._visitor.visit(\u001b[38;5;28mself\u001b[39m.expr)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m visitor(node, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:419\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Module\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33monly a single expression is allowed\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    418\u001b[39m expr = node.body[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m419\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.visit(expr, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m visitor(node, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:422\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Expr\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_Expr\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m422\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.visit(node.value, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m visitor(node, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:746\u001b[39m, in \u001b[36mBaseExprVisitor.visit_BoolOp\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    743\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._maybe_evaluate_binop(op, node.op, lhs, rhs)\n\u001b[32m    745\u001b[39m operands = node.values\n\u001b[32m--> \u001b[39m\u001b[32m746\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m reduce(visitor, operands)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:739\u001b[39m, in \u001b[36mBaseExprVisitor.visit_BoolOp.<locals>.visitor\u001b[39m\u001b[34m(x, y)\u001b[39m\n\u001b[32m    738\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisitor\u001b[39m(x, y):\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     lhs = \u001b[38;5;28mself\u001b[39m._try_visit_binop(x)\n\u001b[32m    740\u001b[39m     rhs = \u001b[38;5;28mself\u001b[39m._try_visit_binop(y)\n\u001b[32m    742\u001b[39m     op, op_class, lhs, rhs = \u001b[38;5;28mself\u001b[39m._maybe_transform_eq_ne(node, lhs, rhs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:735\u001b[39m, in \u001b[36mBaseExprVisitor._try_visit_binop\u001b[39m\u001b[34m(self, bop)\u001b[39m\n\u001b[32m    733\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(bop, (Op, Term)):\n\u001b[32m    734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m bop\n\u001b[32m--> \u001b[39m\u001b[32m735\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.visit(bop)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m visitor(node, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:719\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Compare\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    717\u001b[39m     op = \u001b[38;5;28mself\u001b[39m.translate_In(ops[\u001b[32m0\u001b[39m])\n\u001b[32m    718\u001b[39m     binop = ast.BinOp(op=op, left=node.left, right=comps[\u001b[32m0\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.visit(binop)\n\u001b[32m    721\u001b[39m \u001b[38;5;66;03m# recursive case: we have a chained comparison, a CMP b CMP c, etc.\u001b[39;00m\n\u001b[32m    722\u001b[39m left = node.left\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m visitor(node, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:535\u001b[39m, in \u001b[36mBaseExprVisitor.visit_BinOp\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    534\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_BinOp\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m535\u001b[39m     op, op_class, left, right = \u001b[38;5;28mself\u001b[39m._maybe_transform_eq_ne(node)\n\u001b[32m    536\u001b[39m     left, right = \u001b[38;5;28mself\u001b[39m._maybe_downcast_constants(left, right)\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._maybe_evaluate_binop(op, op_class, left, right)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:453\u001b[39m, in \u001b[36mBaseExprVisitor._maybe_transform_eq_ne\u001b[39m\u001b[34m(self, node, left, right)\u001b[39m\n\u001b[32m    451\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_maybe_transform_eq_ne\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, left=\u001b[38;5;28;01mNone\u001b[39;00m, right=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    452\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m453\u001b[39m         left = \u001b[38;5;28mself\u001b[39m.visit(node.left, side=\u001b[33m\"\u001b[39m\u001b[33mleft\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m right \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    455\u001b[39m         right = \u001b[38;5;28mself\u001b[39m.visit(node.right, side=\u001b[33m\"\u001b[39m\u001b[33mright\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:413\u001b[39m, in \u001b[36mBaseExprVisitor.visit\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m method = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvisit_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(node).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    412\u001b[39m visitor = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, method)\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m visitor(node, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/expr.py:545\u001b[39m, in \u001b[36mBaseExprVisitor.visit_Name\u001b[39m\u001b[34m(self, node, **kwargs)\u001b[39m\n\u001b[32m    544\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvisit_Name\u001b[39m(\u001b[38;5;28mself\u001b[39m, node, **kwargs) -> Term:\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.term_type(node.id, \u001b[38;5;28mself\u001b[39m.env, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/ops.py:91\u001b[39m, in \u001b[36mTerm.__init__\u001b[39m\u001b[34m(self, name, env, side, encoding)\u001b[39m\n\u001b[32m     89\u001b[39m tname = \u001b[38;5;28mstr\u001b[39m(name)\n\u001b[32m     90\u001b[39m \u001b[38;5;28mself\u001b[39m.is_local = tname.startswith(LOCAL_TAG) \u001b[38;5;129;01mor\u001b[39;00m tname \u001b[38;5;129;01min\u001b[39;00m DEFAULT_GLOBALS\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m \u001b[38;5;28mself\u001b[39m._value = \u001b[38;5;28mself\u001b[39m._resolve_name()\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m.encoding = encoding\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/ops.py:115\u001b[39m, in \u001b[36mTerm._resolve_name\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    110\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.env.scope \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    111\u001b[39m     \u001b[38;5;28mself\u001b[39m.env.scope[local_name], \u001b[38;5;28mtype\u001b[39m\n\u001b[32m    112\u001b[39m ):\n\u001b[32m    113\u001b[39m     is_local = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m res = \u001b[38;5;28mself\u001b[39m.env.resolve(local_name, is_local=is_local)\n\u001b[32m    116\u001b[39m \u001b[38;5;28mself\u001b[39m.update(res)\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(res, \u001b[33m\"\u001b[39m\u001b[33mndim\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m res.ndim > \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/envs/INSY6500/lib/python3.13/site-packages/pandas/core/computation/scope.py:244\u001b[39m, in \u001b[36mScope.resolve\u001b[39m\u001b[34m(self, key, is_local)\u001b[39m\n\u001b[32m    242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.temps[key]\n\u001b[32m    243\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m UndefinedVariableError(key, is_local) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n",
      "\u001b[31mUndefinedVariableError\u001b[39m: name 'is_weekend' is not defined"
     ]
    }
   ],
   "source": [
    "# do not modify this setup code\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path('output')\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "output_file = output_dir / 'weekend_electric_trips.csv'\n",
    "\n",
    "# Task 4c code here...\n",
    "rides\n",
    "wknd_elect = rides_start.query('is_weekend == True and rideable_type == \"electric_bike\"')\n",
    "#result.iloc[:1000]\n",
    "#result = result.reset_index('started_at')\n",
    "\n",
    "\n",
    "# use the variable `output_file` as the filename for step 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90",
   "metadata": {},
   "source": [
    "#### Interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91",
   "metadata": {},
   "source": [
    "Reflect on this problem and answer the following questions:\n",
    "\n",
    "1. `groupby() conceptual model`: Explain in your own words what `groupby()` does. Use the phrase \"split-apply-combine\" in your explanation and describe what happens at each stage.\n",
    "2. `value_counts()` vs `groupby()`: In Task 4b.3, you compared two approaches for counting trips by rider type. When would you use `value_counts()` versus `groupby().size()`? Is there a situation where only one of them would work?\n",
    "3. Index management for export: In Task 4c, why did we use `reset_index()` before exporting? What would happen if you exported with the datetime index still in place and used `index=False`?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92",
   "metadata": {},
   "source": [
    "##### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93",
   "metadata": {},
   "source": [
    "*Problem 4 interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94",
   "metadata": {},
   "source": [
    "#### Follow-Up (Graduate Students Only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95",
   "metadata": {},
   "source": [
    "Compare `CSV` and _pickle_ formats for data storage and retrieval.\n",
    "\n",
    "Pickle is Python's built-in serialization format that saves Python objects exactly as they exist in memory, preserving all data types, structures, and metadata. Unlike CSV (which converts everything to text), pickle is binary (not human readable) and maintains the complete state of your DataFrame. Also, pickle files only work in Python, while CSV is universal. Read more in the [Pandas documentation](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.to_pickle.html).\n",
    "\n",
    "The code below investigates an interesting pattern: Do riders take longer trips from scenic lakefront stations even during rush hours? This could indicate tourists or recreational riders using these popular locations for leisure trips during typical commute times. The analysis filters for trips over 15 minutes that started from lakefront stations during morning (7-9am) or evening (4-6pm) rush hours, sorted by duration to see the longest trips first.\n",
    "\n",
    "Run the code below, then answer the interpretation questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# the following lines were commented out since they were run in 4c\n",
    "# from pathlib import Path\n",
    "# output_dir = Path('output')\n",
    "\n",
    "csv_file = output_dir / 'lakefront_rush_trips.csv'\n",
    "pickle_file = output_dir / 'lakefront_rush_trips.pkl'\n",
    "\n",
    "# Filter for interesting pattern: Long trips (>15 min) during rush hours \n",
    "# from lakefront stations, sorted by duration\n",
    "lakefront_rush = (rides\n",
    "    .loc[(rides.index.hour.isin([7, 8, 9, 16, 17, 18]))]\n",
    "    .loc[(rides['start_station_name'].str.contains('Lake Shore|Lakefront', \n",
    "                                                    case=False, \n",
    "                                                    na=False))]\n",
    "    .loc[rides['trip_duration_min'] > 15]\n",
    "    .sort_values('trip_duration_min', ascending=False)\n",
    "    .head(1000)\n",
    "    .reset_index()\n",
    "    [['started_at', 'ended_at', 'start_station_name', 'end_station_name',\n",
    "      'member_casual', 'rideable_type', 'trip_duration_min']]\n",
    ")\n",
    "\n",
    "print(f\"Found {len(lakefront_rush)} long rush-hour trips from lakefront stations\")\n",
    "\n",
    "# Export to both formats\n",
    "lakefront_rush.to_csv(csv_file, index=False)\n",
    "lakefront_rush.to_pickle(pickle_file)\n",
    "\n",
    "# Compare file sizes\n",
    "csv_size = os.path.getsize(csv_file) / 1024  # Convert to KB\n",
    "pickle_size = os.path.getsize(pickle_file) / 1024\n",
    "print(f\"\\nCSV file size: {csv_size:.2f} KB\")\n",
    "print(f\"Pickle file size: {pickle_size:.2f} KB\")\n",
    "print(f\"Size difference: {abs(csv_size - pickle_size):.2f} KB\")\n",
    "\n",
    "# Compare load times\n",
    "print(\"\\nLoad time comparison:\")\n",
    "print(\"CSV:\")\n",
    "%timeit pd.read_csv(csv_file)\n",
    "print(\"\\nPickle:\")\n",
    "%timeit pd.read_pickle(pickle_file)\n",
    "\n",
    "# Check data type preservation\n",
    "# Note: CSV load without parse_dates loses datetime types\n",
    "csv_loaded = pd.read_csv(csv_file)\n",
    "pickle_loaded = pd.read_pickle(pickle_file)\n",
    "\n",
    "print(\"\\nData types from CSV (without parse_dates):\")\n",
    "print(csv_loaded.dtypes)\n",
    "print(\"\\nData types from Pickle:\")\n",
    "print(pickle_loaded.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97",
   "metadata": {},
   "source": [
    "After running the code, answer these questions:\n",
    "\n",
    "1. Method chaining: The analysis uses method chaining with a specific formatting pattern:\n",
    "\n",
    "   ```python\n",
    "   result = (df\n",
    "       .method1()\n",
    "       .method2()\n",
    "       .method3()\n",
    "   )\n",
    "   ```\n",
    "\n",
    "   This wraps the entire chain in parentheses, allowing each method to appear on its own line without backslashes. Discuss why this makes formatting more readable, how it makes debugging easier, how it relates to seeing changes in the code with git diff, and what downsides heavy chaining might have.\n",
    "3. Data types: Compare the dtypes from CSV versus pickle. What types were preserved by pickle that were lost in CSV? Why is this preservation significant for subsequent analysis?\n",
    "4. Trade-offs: Given your observations about size, speed, and type preservation, when would you choose pickle over CSV for your work? When would CSV still be the better choice despite pickle's advantages?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98",
   "metadata": {},
   "source": [
    "*Graduate follow-up interpretation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99",
   "metadata": {},
   "source": [
    "## Reflection\n",
    "\n",
    "Address the following questions in a markdown cell:\n",
    "\n",
    "1. NumPy vs Pandas\n",
    "   - What was the biggest conceptual shift moving from NumPy arrays to Pandas DataFrames?\n",
    "   - Which Pandas concept was most challenging: indexing (loc/iloc), missing data, datetime operations, or method chaining? How did you work through it?\n",
    "2. Real Data Experience\n",
    "   - How did working with real CSV data (with missing values, datetime strings, etc.) differ from hw2b's synthetic NumPy arrays?\n",
    "   - Based on this assignment, what makes Pandas well-suited for data analysis compared to pure NumPy?\n",
    "3. Learning & Application\n",
    "   - Which new skill from this assignment will be most useful for your own data work?\n",
    "   - On a scale of 1-10, how prepared do you feel to use Pandas for your own projects? What would increase that score?\n",
    "4. Feedback\n",
    "   - Time spent: ___ hours (breakdown optional)\n",
    "   - Most helpful part of the assignment: ___\n",
    "   - One specific improvement suggestion: ___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100",
   "metadata": {},
   "source": [
    "### Your Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101",
   "metadata": {},
   "source": [
    "*Reflection here*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
